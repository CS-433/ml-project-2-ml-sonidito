{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a767d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torchvision import transforms, utils, transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d716ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcdefaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7922b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting function\n",
    "\n",
    "def plot_spectrogram(spec, title, time, frequency, start_longest_mode=None, end_longest_mode=None):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(spec.T, extent=(time[0], time[-1], frequency[0], frequency[-1]), aspect='auto', cmap='jet',\n",
    "              origin='lower')\n",
    "    ax.set_xlim(time[0], time[-1])\n",
    "    ax.set_ylim(frequency[0], frequency[-1])\n",
    "    ax.set_xlabel(\"Time [s]\")\n",
    "    ax.set_ylabel(\"Frequency [Hz]\")\n",
    "    fig.set_dpi(150)\n",
    "    plt.title(title)\n",
    "\n",
    "    # Plot vertical lines if start and end times are provided\n",
    "    if start_longest_mode is not None and end_longest_mode is not None:\n",
    "        ax.axvline(x=start_longest_mode, color='blue', linestyle='--', label='Start of Longest Mode')\n",
    "        ax.axvline(x=end_longest_mode, color='darkblue', linestyle='--', label='End of Longest Mode')\n",
    "        plt.legend(loc='upper left')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbf19a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/dataset_pickle\"\n",
    "FILE_EXT = \"pickle\"\n",
    "\n",
    "def load_shot(shotno, data_path, file_ext):\n",
    "    file_path = os.path.join(data_path, f\"{shotno}.{file_ext}\")\n",
    "    return pd.read_pickle(file_path)\n",
    "\n",
    "class SpectrogramDataset(Dataset):\n",
    "    def __init__(self, data_path, file_ext, window_size, transform=None, stride = 0):\n",
    "        # data loading\n",
    "        self.data_path = data_path\n",
    "        self.file_ext = file_ext\n",
    "        self.window_size = window_size\n",
    "        self.transform = transform\n",
    "        self.stride = stride\n",
    "\n",
    "        # Obtain all shot numbers\n",
    "        self.data_files = [int(os.path.basename(x.split(f\".{file_ext}\")[0]))\n",
    "                          for x in glob.glob(os.path.join(data_path, f\"*.{file_ext}\"))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_files) # Returns the # of files\n",
    "    \n",
    "    \"\"\"\n",
    "    The get method describes how a single experiment is handeled, whereas the dataloader will make sure\n",
    "    that the batching is done correctly!\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        shotno = self.data_files[idx]\n",
    "\n",
    "        # Load data for the experiment\n",
    "        data_shot = load_shot(shotno, self.data_path, self.file_ext)\n",
    "\n",
    "        # Extract inputs\n",
    "        spec_even = data_shot[\"x\"][\"spectrogram\"][\"EvenN\"]\n",
    "        spec_odd = data_shot[\"x\"][\"spectrogram\"][\"OddN\"]\n",
    "        frequency = data_shot[\"x\"][\"spectrogram\"][\"frequency\"]\n",
    "        time = data_shot[\"x\"][\"spectrogram\"][\"time\"]\n",
    "\n",
    "        # Calculate the number of windows based on window size\n",
    "        num_windows = int(np.floor((spec_even.shape[0] - self.window_size) / (self.window_size * (1 - self.overlap_factor)))) \n",
    "        print(len(t), num_windows)\n",
    "\n",
    "        # Extract windows along with their start and end indices\n",
    "        windows = []\n",
    "        for i in range(num_windows):\n",
    "            start_idx = int(i * self.window_size * (1 - self.overlap_factor))\n",
    "            end_idx = start_idx + self.window_size\n",
    "\n",
    "            window_even = spec_even[:, start_idx:end_idx]\n",
    "            window_odd = spec_odd[:, start_idx:end_idx]\n",
    "\n",
    "            if self.transform:\n",
    "                window_even = self.transform(window_even)\n",
    "                window_odd = self.transform(window_odd)\n",
    "\n",
    "            windows.append({\n",
    "                'window_even': window_even,\n",
    "                'window_odd': window_odd,\n",
    "                'frequency': f,\n",
    "                'time': t[start_idx:end_idx],\n",
    "                'start_idx': start_idx,\n",
    "                'end_idx': end_idx,\n",
    "                'shotno': shotno\n",
    "            })\n",
    "\n",
    "        return windows\n",
    "    \n",
    "    \n",
    "\n",
    "# Example usage:\n",
    "# Define hyperparameters\n",
    "DATA_PATH = \"data/dataset_pickle\"\n",
    "FILE_EXT = \"pickle\"\n",
    "window_size = 64  # Length of the window\n",
    "batch_size = 32 # Number of experiments (shots) to include in each batch\n",
    "stride = 0.5 # Factor that determines the overlap when selecting sliding windows\n",
    "\n",
    "# Create dataset and dataloader\n",
    "#transform = transforms.Compose([\n",
    "    # Add any additional transformations you need\n",
    "#])\n",
    "\n",
    "dataset = SpectrogramDataset(data_path = DATA_PATH, file_ext = FILE_EXT, window_size = window_size, transform=None, stride = stride)\n",
    "dataloader = DataLoader(dataset = dataset, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493a9d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramDataset(Dataset):\n",
    "    def __init__(self, data_path, file_ext, window_size, transform=None, overlap_factor=0):\n",
    "        self.data_path = data_path\n",
    "        self.file_ext = file_ext\n",
    "        self.window_size = window_size\n",
    "        self.transform = transform\n",
    "        self.overlap_factor = overlap_factor\n",
    "\n",
    "        self.all_shots = [int(os.path.basename(x.split(f\".{file_ext}\")[0]))\n",
    "                          for x in glob.glob(os.path.join(data_path, f\"*.{file_ext}\"))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(len(self.get_windows(shotno)) for shotno in self.all_shots)\n",
    "\n",
    "    def get_windows(self, shotno):\n",
    "        data_shot = load_shot(shotno, self.data_path, self.file_ext)\n",
    "\n",
    "        inputs = data_shot[\"x\"][\"spectrogram\"]\n",
    "        spec_even = inputs[\"EvenN\"]\n",
    "        spec_odd = inputs[\"OddN\"]\n",
    "        f = inputs[\"frequency\"]\n",
    "        t = inputs[\"time\"]\n",
    "\n",
    "        num_windows = int(np.floor(spec_even.shape[1] / (self.window_size * (1 - self.overlap_factor))))\n",
    "\n",
    "        windows = []\n",
    "        for i in range(num_windows):\n",
    "            start_idx = int(i * self.window_size * (1 - self.overlap_factor))\n",
    "            end_idx = start_idx + self.window_size\n",
    "\n",
    "            window_even = spec_even[:, start_idx:end_idx]\n",
    "            window_odd = spec_odd[:, start_idx:end_idx]\n",
    "\n",
    "            if self.transform:\n",
    "                window_even = self.transform(window_even)\n",
    "                window_odd = self.transform(window_odd)\n",
    "\n",
    "            windows.append({\n",
    "                'window_even': window_even,\n",
    "                'window_odd': window_odd,\n",
    "                'frequency': f,\n",
    "                'time': t[start_idx:end_idx],\n",
    "                'start_idx': start_idx,\n",
    "                'end_idx': end_idx,\n",
    "                'shotno': shotno\n",
    "            })\n",
    "\n",
    "        return windows\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        current_idx = 0\n",
    "        for shotno in self.all_shots:\n",
    "            windows = self.get_windows(shotno)\n",
    "            if current_idx + len(windows) > idx:\n",
    "                return windows[idx - current_idx]\n",
    "            current_idx += len(windows)\n",
    "\n",
    "# Example usage\n",
    "window_size = 64\n",
    "overlap_factor = 0.5\n",
    "batch_size = 1  # Use a batch size of 1\n",
    "\n",
    "dataset = SpectrogramDataset(DATA_PATH, FILE_EXT, window_size, overlap_factor=overlap_factor)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "\n",
    "\n",
    "for sample in dataset:\n",
    "    print(sample['start_idx'], sample['end_idx'])\n",
    "    print(len(sample['time']))\n",
    "    print(sample['shotno'])\n",
    "    print(sample['window_even'])\n",
    "    \n",
    "    \n",
    "#for idx in range(len(dataset)):\n",
    "#    sample = dataset[idx]\n",
    "#    print(sample['window_even'].shape)\n",
    "#    print(sample['start_idx'], sample['end_idx'])\n",
    "#    print(sample['time'])\n",
    "#    print(sample['shotno'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828e3d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_shots = [int(os.path.basename(x.split(f\".{FILE_EXT}\")[0]))\n",
    "             for x in glob.glob(os.path.join(DATA_PATH, f\"*.{FILE_EXT}\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbbd646",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/dataset_pickle\"\n",
    "FILE_EXT = \"pickle\"\n",
    "\n",
    "def load_shot(shotno, data_path, file_ext):\n",
    "    file_path = os.path.join(data_path, f\"{shotno}.{file_ext}\")\n",
    "    return pd.read_pickle(file_path)\n",
    "\n",
    "class SpectrogramDataset(Dataset):\n",
    "    def __init__(self, data_path, file_ext, window_size, transform=None, sampler = None):\n",
    "        # data loading\n",
    "        self.data_path = data_path\n",
    "        self.file_ext = file_ext\n",
    "        self.window_size = window_size\n",
    "        self.transform = transform\n",
    "        #self.stride = stride\n",
    "\n",
    "        # Obtain all shot numbers\n",
    "        self.data_files = [int(os.path.basename(x.split(f\".{file_ext}\")[0]))\n",
    "                          for x in glob.glob(os.path.join(data_path, f\"*.{file_ext}\"))]\n",
    "        # Use custom sampler if provided\n",
    "        self.sampler = sampler\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_files) # Returns the # of files\n",
    "    \n",
    "    \"\"\"\n",
    "    The get method describes how a single experiment is handeled, whereas the dataloader will make sure\n",
    "    that the batching is done correctly!\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        shotno = self.data_files[idx]\n",
    "\n",
    "        # Load data for the experiment\n",
    "        data_shot = load_shot(shotno, self.data_path, self.file_ext)\n",
    "\n",
    "        # Extract inputs\n",
    "        spec_even = torch.tensor(data_shot[\"x\"][\"spectrogram\"][\"EvenN\"], dtype=torch.float32).T # --> [frequency, time]\n",
    "        spec_odd = torch.tensor(data_shot[\"x\"][\"spectrogram\"][\"OddN\"], dtype=torch.float32).T\n",
    "        frequency = data_shot[\"x\"][\"spectrogram\"][\"frequency\"]\n",
    "        time = data_shot[\"x\"][\"spectrogram\"][\"time\"]\n",
    "        \n",
    "        num_windows = len(time) // self.window_size\n",
    "\n",
    "        windows = []\n",
    "        for i in range(num_windows):\n",
    "            start_idx = i*window_size\n",
    "            end_idx = start_idx + self.window_size\n",
    "\n",
    "            window_even = spec_even[:, start_idx:end_idx]\n",
    "            window_odd = spec_odd[:, start_idx:end_idx]\n",
    "            print(window_even.shape, window_odd.shape)\n",
    "            \n",
    "            if self.transform:\n",
    "                window_even = self.transform(window_even)\n",
    "                window_odd = self.transform(window_odd)\n",
    "\n",
    "            windows.append({\n",
    "                'window_even': window_even,\n",
    "                'window_odd': window_odd,\n",
    "                'frequency': frequency,\n",
    "                'time': time[start_idx:end_idx],\n",
    "                'start_idx': start_idx,\n",
    "                'end_idx': end_idx,\n",
    "                'shotno': shotno\n",
    "            })\n",
    "\n",
    "        return windows\n",
    "    \n",
    "    \n",
    "# Example usage\n",
    "DATA_PATH = \"data/dataset_pickle\"\n",
    "FILE_EXT = \"pickle\"\n",
    "WINDOW_SIZE = 64  # Adjust as needed\n",
    "#STRIDE = 32  # Adjust as needed\n",
    "\n",
    "custom_sampler = SubsetRandomSampler(all_shots)\n",
    "\n",
    "dataset = SpectrogramDataset(data_path = DATA_PATH, file_ext = FILE_EXT, window_size = WINDOW_SIZE, sampler = None)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for idx, (batch_even, batch_odd) in enumerate(dataloader):\n",
    "    # Your training/inference code here\n",
    "    print(f\"Batch {idx + 1} - EvenN shape: {len(batch_even)} windows\")\n",
    "    print(f\"Batch {idx + 1} - OddN shape: {len(batch_odd)} windows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee7385de",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "each element in list of batch should be of equal size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 74>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     71\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_sampler\u001b[38;5;241m=\u001b[39mbatch_sampler)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Iterate through the DataLoader\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, (batch_even, batch_odd) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;66;03m# Your training/inference code here\u001b[39;00m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - EvenN shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(batch_even)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m windows\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - OddN shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(batch_odd)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m windows\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Project\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Project\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    572\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Project\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Project\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:172\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    169\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [default_collate(samples) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Project\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:172\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    169\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mdefault_collate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Project\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:168\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    166\u001b[0m elem_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mnext\u001b[39m(it))\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(elem) \u001b[38;5;241m==\u001b[39m elem_size \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m it):\n\u001b[1;32m--> 168\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meach element in list of batch should be of equal size\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    169\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n",
      "\u001b[1;31mRuntimeError\u001b[0m: each element in list of batch should be of equal size"
     ]
    }
   ],
   "source": [
    "def __getitem__(self, idx):\n",
    "    shotno = self.data_files[idx]\n",
    "\n",
    "    # Load data for the experiment\n",
    "    data_shot = load_shot(shotno, self.data_path, self.file_ext)\n",
    "\n",
    "    # Extract inputs\n",
    "    spec_even = torch.tensor(data_shot[\"x\"][\"spectrogram\"][\"EvenN\"], dtype=torch.float32).T  # --> [frequency, time]\n",
    "    spec_odd = torch.tensor(data_shot[\"x\"][\"spectrogram\"][\"OddN\"], dtype=torch.float32).T\n",
    "    frequency = data_shot[\"x\"][\"spectrogram\"][\"frequency\"]\n",
    "    time = data_shot[\"x\"][\"spectrogram\"][\"time\"]\n",
    "\n",
    "    num_windows = len(time) // self.window_size\n",
    "\n",
    "    # Print experiment and window information for debugging\n",
    "    print(f\"Experiment: {shotno}, Total Windows: {num_windows}, Window Size: {self.window_size}\")\n",
    "\n",
    "    # Apply non-overlapping sliding window for EvenN\n",
    "    windows_even = []\n",
    "    for i in range(0, num_windows * self.window_size, self.window_size):\n",
    "        start_idx = i\n",
    "        end_idx = i + self.window_size\n",
    "\n",
    "        slice_data = spec_even[start_idx:end_idx, :]\n",
    "        print(f\"EvenN - Window Size: {slice_data.shape}\")\n",
    "\n",
    "        windows_even.append({\n",
    "            'window_even': slice_data,\n",
    "            'frequency': frequency,\n",
    "            'time': time[start_idx:end_idx],\n",
    "            'start_idx': start_idx,\n",
    "            'end_idx': end_idx,\n",
    "            'shotno': shotno\n",
    "        })\n",
    "\n",
    "    # Apply non-overlapping sliding window for OddN\n",
    "    windows_odd = []\n",
    "    for i in range(0, num_windows * self.window_size, self.window_size):\n",
    "        start_idx = i\n",
    "        end_idx = i + self.window_size\n",
    "\n",
    "        slice_data = spec_odd[start_idx:end_idx, :]\n",
    "        print(f\"OddN - Window Size: {slice_data.shape}\")\n",
    "\n",
    "        windows_odd.append({\n",
    "            'window_odd': slice_data,\n",
    "            'frequency': frequency,\n",
    "            'time': time[start_idx:end_idx],\n",
    "            'start_idx': start_idx,\n",
    "            'end_idx': end_idx,\n",
    "            'shotno': shotno\n",
    "        })\n",
    "\n",
    "    return windows_even, windows_odd\n",
    "\n",
    "\n",
    "# Example usage\n",
    "DATA_PATH = \"data/dataset_pickle\"\n",
    "FILE_EXT = \"pickle\"\n",
    "WINDOW_SIZE = 64  # Adjust as needed\n",
    "\n",
    "all_shots = [int(os.path.basename(x.split(f\".{FILE_EXT}\")[0]))\n",
    "             for x in glob.glob(os.path.join(DATA_PATH, f\"*.{FILE_EXT}\"))]\n",
    "# Set batch_size to the desired number of windows per batch\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoader with RandomSampler and BatchSampler\n",
    "dataset = SpectrogramDataset(data_path=DATA_PATH, file_ext=FILE_EXT, window_size=WINDOW_SIZE)\n",
    "sampler = RandomSampler(dataset)\n",
    "batch_sampler = BatchSampler(sampler, batch_size=batch_size, drop_last=True)  # Set drop_last to True if you want to drop the last batch if it's smaller than batch_size\n",
    "dataloader = DataLoader(dataset, batch_sampler=batch_sampler)\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for idx, (batch_even, batch_odd) in enumerate(dataloader):\n",
    "    # Your training/inference code here\n",
    "    print(f\"Batch {idx + 1} - EvenN shape: {len(batch_even)} windows\")\n",
    "    print(f\"Batch {idx + 1} - OddN shape: {len(batch_odd)} windows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a2aeecb",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "each element in list of batch should be of equal size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Iterate through the DataLoader\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, (batch_even, batch_odd) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;66;03m# Your training/inference code here\u001b[39;00m\n\u001b[0;32m      5\u001b[0m         \n\u001b[0;32m      6\u001b[0m         \u001b[38;5;66;03m# Print batch information\u001b[39;00m\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Number of Windows (EvenN): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(batch_even)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Project\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Project\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    572\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Project\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Project\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:172\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    169\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [default_collate(samples) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Project\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:172\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    169\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mdefault_collate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Project\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:168\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    166\u001b[0m elem_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mnext\u001b[39m(it))\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(elem) \u001b[38;5;241m==\u001b[39m elem_size \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m it):\n\u001b[1;32m--> 168\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meach element in list of batch should be of equal size\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    169\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n",
      "\u001b[1;31mRuntimeError\u001b[0m: each element in list of batch should be of equal size"
     ]
    }
   ],
   "source": [
    "# Iterate through the DataLoader\n",
    "for idx, (batch_even, batch_odd) in enumerate(dataloader):\n",
    "    try:\n",
    "        # Your training/inference code here\n",
    "        \n",
    "        # Print batch information\n",
    "        print(f\"Batch {idx + 1} - Number of Windows (EvenN): {len(batch_even)}\")\n",
    "        print(f\"Batch {idx + 1} - Number of Windows (OddN): {len(batch_odd)}\")\n",
    "\n",
    "        # Print sizes of individual windows in the batch\n",
    "        for window_info in batch_even:\n",
    "            print(f\"EvenN - Window Size: {window_info['window_even'].shape}\")\n",
    "\n",
    "        for window_info in batch_odd:\n",
    "            print(f\"OddN - Window Size: {window_info['window_odd'].shape}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in batch {idx + 1}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90fd896e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "__len__() should return >= 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 60>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     57\u001b[0m dataset \u001b[38;5;241m=\u001b[39m SpectrogramDataset(DATA_PATH, FILE_EXT, WINDOW_SIZE, STEP_SIZE)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# create a dataloader with a batch size of 64\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# iterate through the dataloader and print the shape of each batch\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Project\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:277\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[1;32m--> 277\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    279\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Project\\lib\\site-packages\\torch\\utils\\data\\sampler.py:96\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[1;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement, \u001b[38;5;28mbool\u001b[39m):\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     94\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement))\n\u001b[1;32m---> 96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_samples\u001b[49m, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     98\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue, but got num_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Project\\lib\\site-packages\\torch\\utils\\data\\sampler.py:104\u001b[0m, in \u001b[0;36mRandomSampler.num_samples\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnum_samples\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;66;03m# dataset size might change at runtime\u001b[39;00m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_samples \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_source\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_samples\n",
      "\u001b[1;31mValueError\u001b[0m: __len__() should return >= 0"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# define a custom dataset class that returns sliding windows of spectrograms\n",
    "class SpectrogramDataset(Dataset):\n",
    "    def __init__(self, data_path, file_ext, window_size, step_size):\n",
    "        self.data_path = data_path\n",
    "        self.file_ext = file_ext\n",
    "        self.window_size = window_size\n",
    "        self.step_size = step_size\n",
    "        # get all shot numbers\n",
    "        self.all_shots = [int(os.path.basename(x.split(f\".{file_ext}\")[0]))\n",
    "                          for x in glob.glob(os.path.join(data_path, f\"*.{file_ext}\"))]\n",
    "        # compute the total number of windows\n",
    "        self.num_windows = 0\n",
    "        for shotno in self.all_shots:\n",
    "            spectrogram = self.load_shot(shotno)\n",
    "            self.num_windows += (len(spectrogram) - window_size) // step_size + 1\n",
    "\n",
    "    def load_shot(self, shotno):\n",
    "        # load a pickle file containing a spectrogram\n",
    "        file_path = os.path.join(self.data_path, f\"{shotno}.{self.file_ext}\")\n",
    "        return pd.read_pickle(file_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # get the sliding window of spectrogram at the given index\n",
    "        # first, find the corresponding shot number and the offset within the shot\n",
    "        shot_index = 0\n",
    "        window_index = index\n",
    "        while window_index >= (len(self.load_shot(self.all_shots[shot_index])) - self.window_size) // self.step_size + 1:\n",
    "            window_index -= (len(self.load_shot(self.all_shots[shot_index])) - self.window_size) // self.step_size + 1\n",
    "            shot_index += 1\n",
    "        shotno = self.all_shots[shot_index]\n",
    "        # second, load the spectrogram and slice the window\n",
    "        spectrogram = self.load_shot(shotno)\n",
    "        start = window_index * self.step_size\n",
    "        end = start + self.window_size\n",
    "        window = spectrogram[start:end]\n",
    "        # third, convert the window to a torch tensor\n",
    "        window = torch.from_numpy(window)\n",
    "        return window\n",
    "\n",
    "    def __len__(self):\n",
    "        # return the total number of windows\n",
    "        return self.num_windows\n",
    "\n",
    "# define the data path, file extension, window size, and step size\n",
    "DATA_PATH = \"data/dataset_pickle\"\n",
    "FILE_EXT = \"pickle\"\n",
    "WINDOW_SIZE = 32\n",
    "STEP_SIZE = 16\n",
    "\n",
    "# create an instance of the dataset\n",
    "dataset = SpectrogramDataset(DATA_PATH, FILE_EXT, WINDOW_SIZE, STEP_SIZE)\n",
    "\n",
    "# create a dataloader with a batch size of 64\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "\n",
    "# iterate through the dataloader and print the shape of each batch\n",
    "for batch in dataloader:\n",
    "    print(batch.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9af108",
   "metadata": {},
   "source": [
    "## Number of windows per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f55126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = Way of representing the dataset so it can be loaded with the dataloader\n",
    "\n",
    "# dataloader = Used to load batches of data from our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47574dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_data = dataset[93][54] # First item of the first batch of 32 windows (which all correspond to a SINGLE shotno)\n",
    "# First number is the shotno, the second one is which window we are accessing for that shotno.\n",
    "\n",
    "for key, item in first_data.items():\n",
    "    if isinstance(item, (list, np.ndarray, torch.Tensor)):\n",
    "        if isinstance(item, (np.ndarray, torch.Tensor)):\n",
    "            print(key, item.shape)\n",
    "        else:\n",
    "            print(key, len(item))\n",
    "    elif isinstance(item, int):\n",
    "        print(key, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860c472d",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_shotno = np.random.randint(1,94) # Choose a random experiment\n",
    "idx_windowno = np.random.randint(1,batch_size)\n",
    "# Plot a random window (even frequencies) from a random shotno\n",
    "random_sample = dataset[idx_shotno][idx_windowno]\n",
    "print(f\"Experiment number: {random_sample['shotno']}, and window number: {idx_windowno}\")\n",
    "\n",
    "plot_spectrogram(random_sample[\"window_odd\"], title = \"Random window (even frequencies) from a random shotno\",\\\n",
    "                time = random_sample[\"time\"], frequency = random_sample[\"frequency\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42957e5",
   "metadata": {},
   "source": [
    "### Let's verify that this is correct using the real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a13a27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shot = load_shot(random_sample['shotno'], DATA_PATH, FILE_EXT)\n",
    "\n",
    "# Extracting inputs\n",
    "inputs = data_shot[\"x\"][\"spectrogram\"]\n",
    "spec_even = inputs[\"EvenN\"]\n",
    "spec_odd = inputs[\"OddN\"]\n",
    "f = inputs[\"frequency\"]\n",
    "t = inputs[\"time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5b34eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectrogram(spec_even, \"Even N\", t, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bb08e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
